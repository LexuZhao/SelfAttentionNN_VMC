{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5224e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9fcd6ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- reciprocal lattice ----------\n",
    "def reciprocal_vectors(a):\n",
    "    \"\"\"Generates the 3 shortest moiré reciprocal vectors G_1,2,3, 60° apart, six-fold symmetry\"\"\"\n",
    "    g = 4 * np.pi / (np.sqrt(3) * a)  # (length |G|=4π/√3a)\n",
    "    G1 = np.array([g, 0.0])  # first vector along x-axis\n",
    "\n",
    "    def rot(v, ang):\n",
    "        return np.array(\n",
    "            [\n",
    "                np.cos(ang) * v[0] - np.sin(ang) * v[1],  # rotate G1 by +60°, get G2\n",
    "                np.sin(ang) * v[0] + np.cos(ang) * v[1],  # rotate G1 by –60°, get G3\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    return np.stack([G1, rot(G1, np.pi / 3), rot(G1, -np.pi / 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa647c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(self, L: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # W^(l+1) h^l + b^(l+1)\n",
    "        self.Wl_1p = nn.Linear(L, L)\n",
    "\n",
    "        # (nonlinear) hyperbolic tangent activation function\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, hl: torch.Tensor) -> torch.Tensor:\n",
    "        # input should be of shape (N, L)\n",
    "        # h^l + tanh( W^(l+1) h^l + b^(l+1) )\n",
    "        return hl + self.tanh(self.Wl_1p(hl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53be6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlaterNet(nn.Module):\n",
    "    def __init__(self, a: float, N: int, L: int = 4, num_layers: int = 3) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # first, get G vectors\n",
    "        G_vectors = torch.from_numpy(reciprocal_vectors(a)).float()\n",
    "        self.G1_T = G_vectors[0].unsqueeze(-1)\n",
    "        self.G2_T = G_vectors[1].unsqueeze(-1)\n",
    "\n",
    "        # input embedding matrix\n",
    "        self.W_0 = nn.Linear(4, L, bias=False)\n",
    "\n",
    "        # multilayer perceptron neural network layers\n",
    "        self.MLP_layers = nn.ModuleList(\n",
    "            [FeedForwardLayer(L) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "        # matrix to hold the projection vectors\n",
    "        # w_2j and w_2j+1 for j = 0, ... N-1\n",
    "        self.complex_proj = nn.Parameter(\n",
    "            torch.complex(real=torch.randn(L, N), imag=torch.randn(L, N))\n",
    "        )\n",
    "\n",
    "        # denominator of Eq. 2\n",
    "        # = sqrt(N!)\n",
    "        self.denominator = math.sqrt(math.factorial(N))\n",
    "\n",
    "    def forward(self, R: torch.Tensor) -> torch.Tensor:\n",
    "        # R should be of shape (N, 2)\n",
    "        # first we need to compute the periodic features\n",
    "        G1_R = torch.matmul(R, self.G1_T)\n",
    "        G2_R = torch.matmul(R, self.G2_T)\n",
    "        features_R = torch.cat(\n",
    "            (torch.sin(G1_R), torch.sin(G2_R), torch.cos(G1_R), torch.cos(G2_R)), dim=1\n",
    "        )\n",
    "        # shape should now be (N, 4)\n",
    "\n",
    "        # embed in higher_dimensional space to get h^0\n",
    "        h = self.W_0(features_R)\n",
    "\n",
    "        # pass through MLP layers\n",
    "        for layer in self.MLP_layers:\n",
    "            h = layer(h)\n",
    "\n",
    "        # form complex matrix as in Eq. 2\n",
    "        WF_matrix = torch.matmul(h.to(torch.complex64), self.complex_proj)\n",
    "\n",
    "        # compute determinant\n",
    "        determinant = torch.linalg.det(WF_matrix)\n",
    "\n",
    "        # get result\n",
    "        result = determinant / self.denominator\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f059e38f",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "df118eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SlaterNet(\n",
       "  (W_0): Linear(in_features=4, out_features=5, bias=False)\n",
       "  (MLP_layers): ModuleList(\n",
       "    (0-2): 3 x FeedForwardLayer(\n",
       "      (Wl_1p): Linear(in_features=5, out_features=5, bias=True)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_m = 8.5\n",
    "test_model = SlaterNet(a=a_m, N=10, L=5, num_layers=3)\n",
    "test_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d3ac754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor(1.4927e-36+1.4403e-36j, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "R = torch.randn(10, 2)\n",
    "print(R.dtype)\n",
    "phi_HF = test_model(R)\n",
    "print(phi_HF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchbearer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
