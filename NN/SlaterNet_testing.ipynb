{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5224e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f104b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def b_vectors(a_m): # a_m = lattice constant, b_vectors = reciprocal lattice vectors\n",
    "#     b1 = (2*np.pi/a_m) * np.array([ 1.0, -1/np.sqrt(3.0) ])\n",
    "#     b2 = (2*np.pi/a_m) * np.array([ 0.0, 2/np.sqrt(3.0) ])\n",
    "#     b3 = -(b1+b2)\n",
    "#     return np.stack([b1, b2, b3])\n",
    "\n",
    "def b_vectors(a_m):\n",
    "    \"\"\"from paper: g_j = (4*pi / sqrt(3) / a_m) * [cos(2*pi*j/3), sin(2*pi*j/3)], for j=1,2,3\"\"\"\n",
    "    g_list = []\n",
    "    prefac = 4 * np.pi / (np.sqrt(3) * a_m)\n",
    "    for j in range(1, 4):  # j = 1, 2, 3\n",
    "        angle = 2 * np.pi * j / 3\n",
    "        g = prefac * np.array([np.cos(angle), np.sin(angle)])\n",
    "        g_list.append(g)\n",
    "    return g_list  # returns [g1, g2, g3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa647c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForwardLayer(nn.Module):\n",
    "    def __init__(self, L: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # W^(l+1) h^l + b^(l+1)\n",
    "        self.Wl_1p = nn.Linear(L, L)\n",
    "        # (nonlinear) hyperbolic tangent activation function\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, hl: torch.Tensor) -> torch.Tensor:\n",
    "        # input should be of shape (N, L): h^l + tanh( W^(l+1) h^l + b^(l+1) )\n",
    "        return hl + self.tanh(self.Wl_1p(hl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53be6f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlaterNet(nn.Module):\n",
    "    def __init__(self, a: float, N: int, L: int = 4, num_layers: int = 3) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # get G vectors\n",
    "        G_vectors = torch.from_numpy(b_vectors(a)).float()\n",
    "        self.G1_T = G_vectors[0].unsqueeze(-1)\n",
    "        self.G2_T = G_vectors[1].unsqueeze(-1)\n",
    "\n",
    "        # input embedding matrix: projects 4 features to L-dim\n",
    "        self.W_0 = nn.Linear(4, L, bias=False)\n",
    "        self.MLP_layers = nn.ModuleList( # MLP layers\n",
    "            [FeedForwardLayer(L) for _ in range(num_layers)]\n",
    "        )\n",
    "\n",
    "        # matrix to hold the projection vectors (complex projectors for orbital) \n",
    "        # w_2j and w_2j+1 for j = 0, ... N-1\n",
    "        self.complex_proj = nn.Parameter(\n",
    "            torch.complex(real=torch.randn(L, N), imag=torch.randn(L, N))\n",
    "        )\n",
    "        self.denominator = math.sqrt(math.factorial(N))\n",
    "\n",
    "    def forward(self, R: torch.Tensor) -> torch.Tensor:  # R should be of shape (N, 2)\n",
    "        # compute the periodic features\n",
    "        G1_R = torch.matmul(R, self.G1_T)\n",
    "        G2_R = torch.matmul(R, self.G2_T)\n",
    "        features_R = torch.cat(\n",
    "            (torch.sin(G1_R), torch.sin(G2_R), torch.cos(G1_R), torch.cos(G2_R)), dim=1\n",
    "        ) # shape should now be (N, 4)\n",
    "\n",
    "        # embed in higher_dimensional space to get h^0\n",
    "        h = self.W_0(features_R)\n",
    "\n",
    "        # pass through MLP layers\n",
    "        for layer in self.MLP_layers:\n",
    "            h = layer(h)\n",
    "\n",
    "        # form complex matrix as in Eq. 2\n",
    "        WF_matrix = torch.matmul(h.to(torch.complex64), self.complex_proj)\n",
    "\n",
    "        # compute determinant\n",
    "        determinant = torch.linalg.det(WF_matrix)\n",
    "        result = determinant / self.denominator\n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f059e38f",
   "metadata": {},
   "source": [
    "### Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df118eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SlaterNet(\n",
       "  (W_0): Linear(in_features=4, out_features=5, bias=False)\n",
       "  (MLP_layers): ModuleList(\n",
       "    (0): FeedForwardLayer(\n",
       "      (Wl_1p): Linear(in_features=5, out_features=5, bias=True)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (1): FeedForwardLayer(\n",
       "      (Wl_1p): Linear(in_features=5, out_features=5, bias=True)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "    (2): FeedForwardLayer(\n",
       "      (Wl_1p): Linear(in_features=5, out_features=5, bias=True)\n",
       "      (tanh): Tanh()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_m = 8.031\n",
    "test_model = SlaterNet(a=a_m, N=10, L=5, num_layers=3)\n",
    "test_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d3ac754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "tensor(-1.3063e-36+2.4554e-36j, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "R = torch.randn(10, 2)\n",
    "print(R.dtype)\n",
    "phi_HF = test_model(R)\n",
    "print(phi_HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880819e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
